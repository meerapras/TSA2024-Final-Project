---
title: "precipitation"
author: "Ina Liao"
date: "2024-04-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Install Packages}
#install.packages("rvest")
library(tidyverse)
library(lubridate)
library(here); here()
library(rvest)
```

```{r Fetch the website resource - Location}
the_base_url<-'https://www.cnrfc.noaa.gov/'
scrape.it<-function(the_year){
  #retrieve the website contents
  the_website<-read_html(paste0('https://www.cnrfc.noaa.gov/',
                            'monthly_precip_',the_year,'.php'))
  
  #set the elements address variables 
  the_location_tag <-'td:nth-child(2)'
  the_Jan_data<-'td:nth-child(6)'
  the_Feb_data<-'td:nth-child(7)'
  the_Mar_data<-'td:nth-child(8)'
  the_Apr_data<-'td:nth-child(9)'
  the_May_data<-'td:nth-child(10)'
  the_Jun_data<-'td:nth-child(11)'
  the_Jul_data<-'td:nth-child(12)'
  the_Aug_data<-'td:nth-child(13)'
  the_Sep_data<-'td:nth-child(14)'
  
  #scrape the data items
  the_location<- the_website %>%
    html_nodes(the_location_tag) %>%
    html_text()
  the_Jan<- the_website %>%
    html_nodes(the_Jan_data) %>%
    html_text()
  the_Feb<- the_website %>%
    html_nodes(the_Feb_data) %>%
    html_text()
  the_Mar<- the_website %>%
    html_nodes(the_Mar_data) %>%
    html_text()
  the_Apr<- the_website %>%
    html_nodes(the_Apr_data) %>%
    html_text()
  the_May<- the_website %>%
    html_nodes(the_May_data) %>%
    html_text()
  the_Jun<- the_website %>%
    html_nodes(the_Jun_data) %>%
    html_text()
  the_Jul<- the_website %>%
    html_nodes(the_Jul_data) %>%
    html_text()
  the_Aug<- the_website %>%
    html_nodes(the_Aug_data) %>%
    html_text()
  the_Sep<- the_website %>%
    html_nodes(the_Sep_data) %>%
    html_text()
  
  #convert to a dataframe
  df_precipitation<- data.frame("Order"= rep(1:355)) %>%
    mutate(Location=!!the_location,
           Jan=!!the_Jan,
           Feb=!!the_Feb,
           Mar=!!the_Mar,
           Apr=!!the_Apr,
           May=!!the_May,
           Jun=!!the_Jun,
           Jul=!!the_Jul,
           Aug=!!the_Aug,
           Sep=!!the_Sep)
  return(df_precipitation)
}
```


```{r Scrape Data - Jan to Sep}
#Use lapply to apply the scrape 
the_years = rep(2005:2021)
the_dfs <-lapply(X=the_years,
                 FUN=scrape.it)

#Conflate the returned dataframes into a single dataframe
the_df <- bind_rows(the_dfs)

```

```{r Fetch the website resource - Location}
the_base_url<-'https://www.cnrfc.noaa.gov/'
scrape.it_2<-function(the_year){
  #retrieve the website contents
  the_website<-read_html(paste0('https://www.cnrfc.noaa.gov/',
                            'monthly_precip_',the_year,'.php'))
  
  #set the elements address variables 
  the_location_tag <-'td:nth-child(2)'
  the_Oct_data<-'td:nth-child(3)'
  the_Nov_data<-'td:nth-child(4)'
  the_Dec_data<-'td:nth-child(5)'
  
  #scrape the data items
  the_location<- the_website %>%
    html_nodes(the_location_tag) %>%
    html_text()
  the_Oct<- the_website %>%
    html_nodes(the_Oct_data) %>%
    html_text()
  the_Nov<- the_website %>%
    html_nodes(the_Nov_data) %>%
    html_text()
  the_Dec<- the_website %>%
    html_nodes(the_Dec_data) %>%
    html_text()
  #convert to a dataframe
  df_precipitation<- data.frame("Order"= rep(1:380)) %>%
    mutate(Location=!!the_location,
           Oct=!!the_Oct,
           Nov=!!the_Nov,
           Dec=!!the_Dec)
  return(df_precipitation)
}
```
